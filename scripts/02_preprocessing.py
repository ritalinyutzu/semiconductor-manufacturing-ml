#!/usr/bin/env python3
"""
ç¬¬äºŒæ­¥ï¼šæ•¸æ“šé è™•ç†
é‹è¡Œ: python scripts/02_preprocessing.py
"""

import sys
sys.path.append('..')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import joblib
from src.preprocessing import DataPreprocessor
from src.utils import print_header, print_section, split_data
import warnings

warnings.filterwarnings('ignore')


def main():
    print_header("ğŸ› ï¸ ç¬¬äºŒæ­¥ï¼šæ•¸æ“šé è™•ç†")
    
    # æ­¥é©Ÿ1: è¼‰å…¥æ•¸æ“š
    print_section("æ­¥é©Ÿ1: è¼‰å…¥æ•¸æ“š")
    df = pd.read_csv('data/raw/secom.csv')
    print(f"âœ… æ•¸æ“šè¼‰å…¥å®Œæˆ: {df.shape}")
    
    # æ­¥é©Ÿ2: åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
    print_section("æ­¥é©Ÿ2: åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸")
    target_col = df.columns[-1]
    X = df.drop(columns=[target_col])
    y = df[target_col]
    print(f"âœ… ç‰¹å¾µå½¢ç‹€: {X.shape}")
    print(f"âœ… ç›®æ¨™è®Šæ•¸å½¢ç‹€: {y.shape}")
    print(f"   ç›®æ¨™é¡åˆ¥åˆ†å¸ƒ: {dict(y.value_counts().sort_index())}")
    
    # æ­¥é©Ÿ3: è™•ç†ç¼ºå¤±å€¼
    print_section("æ­¥é©Ÿ3: è™•ç†ç¼ºå¤±å€¼")
    preprocessor = DataPreprocessor()
    preprocessor.check_missing_values(X)
    X = preprocessor.handle_missing_values(X, strategy='drop', threshold=0.5)
    
    # åŒæ­¥y
    y = y[X.index]
    X = X.reset_index(drop=True)
    y = y.reset_index(drop=True)
    
    print(f"âœ… è™•ç†å®Œæˆ: X={X.shape}, y={y.shape}")
    
    # æ­¥é©Ÿ4: åªä¿ç•™æ•¸å€¼ç‰¹å¾µï¼ˆç§»é™¤æ™‚é–“æˆ³ç­‰æ–‡å­—æ¬„ä½ï¼‰
    print_section("æ­¥é©Ÿ4: åªä¿ç•™æ•¸å€¼ç‰¹å¾µ")
    X = X.select_dtypes(include=[np.number])
    print(f"âœ… ç‰¹å¾µéæ¿¾å®Œæˆ: {X.shape}")
    
    # æ­¥é©Ÿ5: ç§»é™¤é›¶æ–¹å·®ç‰¹å¾µ
    print_section("æ­¥é©Ÿ5: ç§»é™¤é›¶æ–¹å·®ç‰¹å¾µ")
    X = preprocessor.remove_zero_variance_features(X)
    
    # æ­¥é©Ÿ6: åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
    print_section("æ­¥é©Ÿ6: åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†")
    X_train, X_test, y_train, y_test = split_data(
        X, y, test_size=0.2, random_state=42, stratify=True
    )
    
    print(f"âœ… è¨“ç·´é›†ç›®æ¨™åˆ†å¸ƒ: {dict(y_train.value_counts().sort_index())}")
    print(f"âœ… æ¸¬è©¦é›†ç›®æ¨™åˆ†å¸ƒ: {dict(y_test.value_counts().sort_index())}")
    
    # æ­¥é©Ÿ7: ç‰¹å¾µç¸®æ”¾
    print_section("æ­¥é©Ÿ7: ç‰¹å¾µç¸®æ”¾")
    X_train_scaled, X_test_scaled = preprocessor.scale_features(
        X_train, X_test, fit=True
    )
    
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)
    
    print(f"âœ… ç¸®æ”¾å®Œæˆ")
    print(f"   è¨“ç·´é›†å¹³å‡å€¼: {X_train_scaled.mean().mean():.4f}")
    print(f"   è¨“ç·´é›†æ¨™æº–å·®: {X_train_scaled.std().mean():.4f}")
    
    # æ­¥é©Ÿ8: PCAé™ç¶­
    print_section("æ­¥é©Ÿ8: PCAé™ç¶­")
    X_train_pca, X_test_pca = preprocessor.apply_pca(
        X_train_scaled, X_test_scaled, variance_ratio=0.95, fit=True
    )
    
    pca_columns = [f'PC{i+1}' for i in range(X_train_pca.shape[1])]
    X_train_pca = pd.DataFrame(X_train_pca, columns=pca_columns)
    X_test_pca = pd.DataFrame(X_test_pca, columns=pca_columns)
    
    print(f"âœ… PCAé™ç¶­å®Œæˆ")
    
    # å¯è¦–åŒ–PCAè§£é‡‹æ–¹å·®
    print_section("æ­¥é©Ÿ9: å¯è¦–åŒ–PCA")
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    ax = axes[0]
    ax.bar(range(1, len(preprocessor.pca.explained_variance_ratio_) + 1),
           preprocessor.pca.explained_variance_ratio_, color='#4ECDC4')
    ax.set_xlabel('ä¸»æˆåˆ†')
    ax.set_ylabel('è§£é‡‹æ–¹å·®æ¯”')
    ax.set_title('PCA - å€‹é«”è§£é‡‹æ–¹å·®')
    ax.grid(alpha=0.3, axis='y')
    
    ax = axes[1]
    cumsum = np.cumsum(preprocessor.pca.explained_variance_ratio_)
    ax.plot(range(1, len(cumsum) + 1), cumsum, marker='o', linewidth=2, markersize=8, color='#FF6B6B')
    ax.axhline(y=0.95, color='green', linestyle='--', label='95% æ–¹å·®')
    ax.set_xlabel('ä¸»æˆåˆ†')
    ax.set_ylabel('ç´¯ç©è§£é‡‹æ–¹å·®')
    ax.set_title('PCA - ç´¯ç©è§£é‡‹æ–¹å·®')
    ax.legend()
    ax.grid(alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/figures/03_pca_variance.png', dpi=300, bbox_inches='tight')
    print("âœ… PCAå¯è¦–åŒ–å·²ä¿å­˜: results/figures/03_pca_variance.png")
    plt.close()
    
    # æ­¥é©Ÿ10: ä¿å­˜æ•¸æ“š
    print_section("æ­¥é©Ÿ10: ä¿å­˜é è™•ç†å¾Œçš„æ•¸æ“š")
    
    X_train_pca.to_csv('data/processed/X_train_pca.csv', index=False)
    X_test_pca.to_csv('data/processed/X_test_pca.csv', index=False)
    y_train.to_csv('data/processed/y_train.csv', index=False, header=['target'])
    y_test.to_csv('data/processed/y_test.csv', index=False, header=['target'])
    
    print("âœ… æ•¸æ“šå·²ä¿å­˜")
    print("   - X_train_pca.csv")
    print("   - X_test_pca.csv")
    print("   - y_train.csv")
    print("   - y_test.csv")
    
    joblib.dump(preprocessor.scaler, 'data/processed/scaler.pkl')
    joblib.dump(preprocessor.pca, 'data/processed/pca.pkl')
    
    print("\nâœ… é è™•ç†å™¨å·²ä¿å­˜")
    print("   - scaler.pkl")
    print("   - pca.pkl")
    
    print_section("é è™•ç†æ‘˜è¦")
    
    summary = f"""
ğŸ“Š é è™•ç†å®Œæˆå ±å‘Š
{'â”€'*60}

æ•¸æ“šè™•ç†æ­¥é©Ÿ:
  1. âœ… è™•ç†ç¼ºå¤±å€¼
  2. âœ… åªä¿ç•™æ•¸å€¼ç‰¹å¾µ
  3. âœ… ç§»é™¤é›¶æ–¹å·®ç‰¹å¾µ
  4. âœ… åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
  5. âœ… ç‰¹å¾µç¸®æ”¾
  6. âœ… PCAé™ç¶­

é™ç¶­æˆæœ:
  - åŸå§‹ç‰¹å¾µæ•¸: {X_train_scaled.shape[1]}
  - é™ç¶­å¾Œç‰¹å¾µæ•¸: {X_train_pca.shape[1]}
  - ç¶­åº¦å£“ç¸®æ¯”: {X_train_scaled.shape[1]/X_train_pca.shape[1]:.2f}:1
"""
    
    print(summary)
    
    with open('results/preprocessing_report.txt', 'w', encoding='utf-8') as f:
        f.write(summary)
    print("âœ… å ±å‘Šå·²ä¿å­˜: results/preprocessing_report.txt")
    
    print("\n" + "="*60)
    print("âœ… æ•¸æ“šé è™•ç†å®Œæˆï¼")
    print("="*60)


if __name__ == '__main__':
    main()