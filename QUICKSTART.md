# å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“¦ é¡¹ç›®å·²å®Œæˆçš„æ¡†æ¶

âœ… å®Œæ•´çš„é¡¹ç›®ç»“æ„
âœ… 5ä¸ªæ ¸å¿ƒPythonæ¨¡å—ï¼ˆé¢„å¤„ç†ã€æ¨¡å‹ã€è¯„ä¼°ã€å·¥å…·ï¼‰
âœ… è¯¦ç»†çš„ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£
âœ… Gitä»“åº“å·²åˆå§‹åŒ–

---

## ğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ

### 1ï¸âƒ£ å…³è”åˆ°GitHubä»“åº“

ä½ å·²ç»åœ¨GitHubä¸Šåˆ›å»ºäº†ç©ºä»“åº“ `semiconductor-manufacturing-ml`

åœ¨ä½ çš„ç”µè„‘ä¸Šæ‰§è¡Œï¼š

```bash
# è¿›å…¥é¡¹ç›®æ–‡ä»¶å¤¹
cd /home/claude/semiconductor-manufacturing-ml

# æ·»åŠ è¿œç¨‹ä»“åº“ï¼ˆæ›¿æ¢YOUR_USERNAMEä¸ºä½ çš„GitHubç”¨æˆ·åï¼‰
git remote add origin https://github.com/YOUR_USERNAME/semiconductor-manufacturing-ml.git

# æ”¹ååˆ†æ”¯ï¼ˆå¦‚éœ€è¦ï¼‰
git branch -M main

# æ¨é€åˆ°GitHub
git push -u origin main
```

### 2ï¸âƒ£ å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ ä¸‹è½½æ•°æ®

ä» Kaggle ä¸‹è½½ [UCI SECOM Dataset](https://www.kaggle.com/datasets/paresh2047/uci-semcom)

å°†æ–‡ä»¶æ”¾åœ¨ `data/raw/` æ–‡ä»¶å¤¹

---

## ğŸ“Š é¡¹ç›®å·¥ä½œæµç¨‹

æˆ‘ä»¬å°†æŒ‰ä»¥ä¸‹é¡ºåºå®Œæˆï¼š

```
01. EDA (æ¢ç´¢æ€§æ•°æ®åˆ†æ)
    â”œâ”€ åŠ è½½æ•°æ®
    â”œâ”€ æ£€æŸ¥ç¼ºå¤±å€¼
    â”œâ”€ ç±»åˆ«åˆ†å¸ƒåˆ†æ
    â””â”€ åŸºæœ¬ç»Ÿè®¡

02. æ•°æ®é¢„å¤„ç†
    â”œâ”€ å¤„ç†ç¼ºå¤±å€¼
    â”œâ”€ ç§»é™¤é›¶æ–¹å·®ç‰¹å¾
    â”œâ”€ ç‰¹å¾ç¼©æ”¾
    â””â”€ PCAé™ç»´

03. æ¨¡å‹è®­ç»ƒ
    â”œâ”€ KNN
    â”œâ”€ Naive Bayes
    â”œâ”€ Logistic Regression
    â”œâ”€ Random Forest
    â””â”€ XGBoost

04. ç»“æœåˆ†æ
    â”œâ”€ æ··æ·†çŸ©é˜µ
    â”œâ”€ ROCæ›²çº¿
    â”œâ”€ ç‰¹å¾é‡è¦æ€§
    â””â”€ æœ€ç»ˆæ€»ç»“
```

---

## ğŸ”§ æ ¸å¿ƒæ¨¡å—è¯´æ˜

### `src/preprocessing.py`
- `DataPreprocessor`: æ•°æ®å¤„ç†ç±»
  - `load_data()` - åŠ è½½æ•°æ®
  - `handle_missing_values()` - å¤„ç†ç¼ºå¤±å€¼
  - `remove_zero_variance_features()` - ç§»é™¤é›¶æ–¹å·®ç‰¹å¾
  - `scale_features()` - ç‰¹å¾ç¼©æ”¾
  - `apply_pca()` - PCAé™ç»´

### `src/models.py`
- `ModelTrainer`: æ¨¡å‹è®­ç»ƒå™¨
  - `train_and_evaluate_all()` - è®­ç»ƒæ‰€æœ‰æ¨¡å‹
  - `get_best_model()` - è·å–æœ€ä½³æ¨¡å‹
- `HyperparameterTuner`: è¶…å‚æ•°è°ƒä¼˜

### `src/evaluate.py`
- `ModelEvaluator`: æ¨¡å‹è¯„ä¼°
  - `plot_confusion_matrix()` - æ··æ·†çŸ©é˜µ
  - `plot_roc_curve()` - ROCæ›²çº¿
  - `compare_models()` - æ¨¡å‹å¯¹æ¯”

### `src/utils.py`
- æ•°æ®åˆ†æå’Œå¯è§†åŒ–å·¥å…·å‡½æ•°

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

```python
# å¯¼å…¥æ¨¡å—
from src.preprocessing import DataPreprocessor
from src.models import ModelTrainer
from src.evaluate import ModelEvaluator
from src.utils import split_data

# 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
preprocessor = DataPreprocessor()
df = preprocessor.load_data('data/raw/secom.csv')
df = preprocessor.handle_missing_values(df)
df = preprocessor.remove_zero_variance_features(df, exclude_cols=['ç»“æœåˆ—'])

# 2. ç‰¹å¾ç¼©æ”¾å’ŒPCA
X_train_scaled = preprocessor.scale_features(X_train)
X_train_pca = preprocessor.apply_pca(X_train_scaled, variance_ratio=0.95)

# 3. è®­ç»ƒæ¨¡å‹
trainer = ModelTrainer()
results_df, trained_models = trainer.train_and_evaluate_all(
    X_train_pca, y_train, X_test_pca, y_test
)

# 4. è·å–æœ€ä½³æ¨¡å‹
best_model_name, best_model = trainer.get_best_model()

# 5. è¯„ä¼°
evaluator = ModelEvaluator()
evaluator.plot_confusion_matrix(y_test, y_pred, model_name=best_model_name)
evaluator.plot_roc_curve(y_test, y_proba, model_name=best_model_name)
```

---

## âœ¨ å‡†å¤‡å¥½å¼€å§‹äº†å—ï¼Ÿ

å‘Šè¯‰æˆ‘ä½ å·²ç»ï¼š
1. âœ… åœ¨GitHubåˆ›å»ºäº†ç©ºä»“åº“
2. âœ… æƒ³ä»å“ªä¸€æ­¥å¼€å§‹ï¼ˆEDA / é¢„å¤„ç† / æ¨¡å‹ / è¯„ä¼°ï¼‰

æˆ‘ä¼šä¸ºä½ åˆ›å»ºå®Œæ•´çš„Jupyter notebookå’Œè¯¦ç»†çš„ä»£ç æŒ‡å¯¼ï¼

